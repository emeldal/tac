{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b035f594501fd99b0ba4fdbf39dd3ef4592c3539e4ec00f8ba05c88e0c5143ba"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Visualiser les termes les plus fréquents"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Rapport Final"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Installation des dépendences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Mots clefs décade"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1850"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\emeld\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Output has been written in 185_keywords.txt!'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "data_path = \"../data/txt/\"\n",
    "\n",
    "DECADE = '1850'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emeld\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "5420177 words found\n",
      "1031297 words kept (61021 different word forms)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('francs', 6949),\n",
       " ('collège', 6325),\n",
       " ('travaux', 4870),\n",
       " ('rapport', 4241),\n",
       " ('administration', 4186),\n",
       " ('hospices', 3673),\n",
       " ('art', 3528),\n",
       " ('projet', 2986)]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"les\", \"plus\", \"cette\", \"fait\", \"faire\", \"être\", \"deux\", \"comme\", \"dont\", \"tout\", \n",
    "       \"ils\", \"bien\", \"sans\", \"peut\", \"tous\", \"après\", \"ainsi\", \"donc\", \"cet\", \"sous\",\n",
    "       \"celle\", \"entre\", \"encore\", \"toutes\", \"pendant\", \"moins\", \"dire\", \"cela\", \"non\",\n",
    "       \"faut\", \"trois\", \"aussi\", \"dit\", \"avoir\", \"doit\", \"contre\", \"depuis\", \"autres\",\n",
    "       \"van\", \"het\", \"autre\", \"jusqu\", \"ville\", \"vers\", \"quelque\", \"car\", \"quel\", \"abord\", \"parce\", \n",
    "       \"leurs\", \"chez\", \"aucun\", \"alors\", \"auquel\", \"tandis\", \"quand\", \"devons\", \"donne\", \n",
    "       \"telles\", \"toujours\", \"seulement\", \"pourra\", \"cependant\", \"plusieurs\", \"elles\", \n",
    "       \"déjà\", \"très\", \"lorsque\", \"trouve\", \"crois\", \"toute\", \"faite\", \"ans\", \"celles\",\n",
    "       \"celui\", \"quelques\", \"laquelle\", \"faites\", \"tel\", \"etc\", \"devront\", \"chaque\", \"agit\",\n",
    "       \"mettre\", \"ceux\", \"pourront\", \"avant\", \"prendre\", \"aucune\", \"peu\", \"fera\", \"également\",\n",
    "       \"celles\", \"dessus\", \"devant\", \"beaucoup\", \"rue\", \"échevin\", \"echevin\", \"conseil\",\n",
    "       \"conseil_communal\", \"bruxelles\", \"propose\", \"agit\", \"puis\", \"place\", \"gouvernement\",\n",
    "       \"pourrait\", \"ailleurs\", \"question\", \"suite\", \"année\", \"avis_favorable\", \"bourgmestre\",\n",
    "       \"janvier\", \"février\", \"mars\", \"avril\", \"juin\", \"juillet\", \"août\", \"aout\", \"septembre\",\n",
    "       \"octobre\", \"décembre\", \"novembre\", \"personne\", \"cas\", \"ailleur\", \"dernier\", \"lieu\", \"partie\",\n",
    "       \"dernière\", \"derniere\", \"derniers\", \"dernières\", \"dernieres\", \"communal\", \"service\",\n",
    "       \"section\", \"messieurs\", \"actuellement\", \"moment\", \"jour\", \"grande\", \"grand\", \"grands\",\n",
    "       \"grandes\", \"donner\", \"mai\", \"assez\", \"quant\", \"deux\", \"trois\", \"quatre\", \"cinq\", \"six\", \"sept\",\n",
    "       \"huit\", \"dix\", \"jamais\", \"voir\", \"bas\", \"près\", \"loin\", \"tant\", \"ici\", \"reçu\", \"afin\", \"mis\",\n",
    "       \"dès\", \"veut\"]\n",
    "sw = set(sw)\n",
    "path = \"185.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(8)"
   ]
  },
  {
   "source": [
    "1860"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4351569 words found\n",
      "1084021 words kept (50489 different word forms)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('collège', 7553),\n",
       " ('francs', 6830),\n",
       " ('travaux', 5325),\n",
       " ('rapport', 4942),\n",
       " ('art', 4916)]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "DECADE = '1860'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"186.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(5)"
   ]
  },
  {
   "source": [
    "1870"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5134740 words found\n",
      "1246787 words kept (51861 different word forms)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('francs', 9445),\n",
       " ('collège', 8108),\n",
       " ('art', 5920),\n",
       " ('travaux', 5702),\n",
       " ('administration', 4754),\n",
       " ('rapport', 4366),\n",
       " ('demande', 3818),\n",
       " ('somme', 3564),\n",
       " ('séance', 3486),\n",
       " ('compte', 3392),\n",
       " ('publique', 3275),\n",
       " ('frais', 3254),\n",
       " ('avis', 3221),\n",
       " ('hospices', 3066),\n",
       " ('finances', 3057),\n",
       " ('budget', 3011),\n",
       " ('école', 2958),\n",
       " ('projet', 2898),\n",
       " ('dépenses', 2869),\n",
       " ('terrain', 2862)]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "DECADE = '1870'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"187.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(20)"
   ]
  },
  {
   "source": [
    "1880"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12509283 words found\n",
      "2811614 words kept (101935 different word forms)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('francs', 24629),\n",
       " ('collège', 16817),\n",
       " ('art', 14315),\n",
       " ('travaux', 9749),\n",
       " ('administration', 9549),\n",
       " ('rapport', 9331),\n",
       " ('frais', 9090),\n",
       " ('budget', 8942),\n",
       " ('dépenses', 8400),\n",
       " ('demande', 8347),\n",
       " ('somme', 7709),\n",
       " ('compte', 7595),\n",
       " ('commune', 7475),\n",
       " ('séance', 7154),\n",
       " ('avis', 7055),\n",
       " ('publique', 6719),\n",
       " ('prix', 6695),\n",
       " ('proposition', 6547),\n",
       " ('école', 6536),\n",
       " ('hospices', 6257),\n",
       " ('finances', 6149),\n",
       " ('police', 5924),\n",
       " ('total', 5882),\n",
       " ('honorable', 5765),\n",
       " ('droit', 5545),\n",
       " ('recettes', 5479),\n",
       " ('projet', 5302),\n",
       " ('gaz', 5236),\n",
       " ('nombre', 5191),\n",
       " ('communale', 5088),\n",
       " ('dépense', 5013),\n",
       " ('société', 4815),\n",
       " ('exercice', 4813),\n",
       " ('terrain', 4805),\n",
       " ('entretien', 4741),\n",
       " ('part', 4722),\n",
       " ('situation', 4647),\n",
       " ('celte', 4628),\n",
       " ('écoles', 4555),\n",
       " ('loi', 4522),\n",
       " ('point', 4494),\n",
       " ('cours', 4314),\n",
       " ('ordre', 4311),\n",
       " ('enfants', 4275),\n",
       " ('personnel', 4270),\n",
       " ('membres', 4269),\n",
       " ('terrains', 4236),\n",
       " ('conditions', 4188),\n",
       " ('bureau', 4100),\n",
       " ('crédit', 4074),\n",
       " ('laeken', 4058),\n",
       " ('taxe', 4053),\n",
       " ('maison', 4001),\n",
       " ('honneur', 4000),\n",
       " ('règlement', 3982),\n",
       " ('commission', 3961),\n",
       " ('fabrique', 3936),\n",
       " ('vente', 3881),\n",
       " ('mois', 3867),\n",
       " ('vue', 3817),\n",
       " ('église', 3807),\n",
       " ('richald', 3805),\n",
       " ('hui', 3795),\n",
       " ('saint', 3783),\n",
       " ('aujourd', 3780),\n",
       " ('objet', 3720),\n",
       " ('état', 3702),\n",
       " ('traitement', 3697),\n",
       " ('approbation', 3682),\n",
       " ('etat', 3639),\n",
       " ('quartier', 3598),\n",
       " ('construction', 3493),\n",
       " ('produit', 3441),\n",
       " ('charges', 3436),\n",
       " ('subside', 3421),\n",
       " ('temps', 3351),\n",
       " ('secours', 3350),\n",
       " ('discussion', 3337),\n",
       " ('mot', 3317),\n",
       " ('nouveau', 3290),\n",
       " ('favorable', 3248),\n",
       " ('général', 3237),\n",
       " ('nom', 3174),\n",
       " ('travail', 3122),\n",
       " ('voie', 3119),\n",
       " ('walravens', 3023),\n",
       " ('eau', 3022),\n",
       " ('chef', 3021),\n",
       " ('intérêts', 2984),\n",
       " ('services', 2974),\n",
       " ('rien', 2957),\n",
       " ('classe', 2930),\n",
       " ('public', 2921),\n",
       " ('effet', 2920),\n",
       " ('publics', 2915),\n",
       " ('fonds', 2910),\n",
       " ('intérêt', 2907),\n",
       " ('ordinaires', 2894),\n",
       " ('enseignement', 2888),\n",
       " ('maisons', 2866),\n",
       " ('accord', 2866),\n",
       " ('chiffre', 2865),\n",
       " ('affaire', 2837),\n",
       " ('arrêté', 2819),\n",
       " ('heures', 2805),\n",
       " ('rues', 2795),\n",
       " ('président', 2774),\n",
       " ('date', 2771),\n",
       " ('proposer', 2734),\n",
       " ('possible', 2728),\n",
       " ('élèves', 2722),\n",
       " ('observations', 2721),\n",
       " ('exécution', 2718),\n",
       " ('marché', 2716),\n",
       " ('payer', 2691),\n",
       " ('sections', 2689),\n",
       " ('comité', 2676),\n",
       " ('divers', 2632),\n",
       " ('vote', 2629),\n",
       " ('années', 2624),\n",
       " ('propriétés', 2610),\n",
       " ('examen', 2607),\n",
       " ('raison', 2585),\n",
       " ('mètres', 2576),\n",
       " ('autorisation', 2560),\n",
       " ('savoir', 2551),\n",
       " ('augmentation', 2517),\n",
       " ('caisse', 2497),\n",
       " ('moyen', 2495),\n",
       " ('concession', 2494),\n",
       " ('secrétaire', 2493),\n",
       " ('population', 2484),\n",
       " ('nouvelle', 2481),\n",
       " ('diverses', 2465),\n",
       " ('bienfaisance', 2451),\n",
       " ('établissement', 2448),\n",
       " ('fois', 2442),\n",
       " ('article', 2434),\n",
       " ('instruction', 2412),\n",
       " ('extraordinaires', 2403),\n",
       " ('centimes', 2398),\n",
       " ('communes', 2350),\n",
       " ('concerne', 2347),\n",
       " ('voix', 2336),\n",
       " ('vauthier', 2335),\n",
       " ('personnes', 2327),\n",
       " ('doivent', 2321),\n",
       " ('mesure', 2275),\n",
       " ('ressources', 2264),\n",
       " ('charge', 2252),\n",
       " ('canal', 2251),\n",
       " ('constructions', 2251),\n",
       " ('valeur', 2246),\n",
       " ('pouvoir', 2244),\n",
       " ('allard', 2240),\n",
       " ('cahier', 2240),\n",
       " ('premier', 2231),\n",
       " ('nécessaire', 2227),\n",
       " ('royal', 2195),\n",
       " ('avenue', 2177),\n",
       " ('conclusions', 2157),\n",
       " ('manière', 2154),\n",
       " ('permanente', 2145),\n",
       " ('sujet', 2144),\n",
       " ('cimetière', 2139),\n",
       " ('communales', 2137),\n",
       " ('droits', 2132),\n",
       " ('suivant', 2131),\n",
       " ('lettre', 2127),\n",
       " ('vient', 2105),\n",
       " ('chose', 2101),\n",
       " ('éclairage', 2099),\n",
       " ('fer', 2094),\n",
       " ('location', 2084),\n",
       " ('finet', 2066),\n",
       " ('renvoi', 2060),\n",
       " ('lepage', 2057),\n",
       " ('procès', 2040),\n",
       " ('nature', 2026),\n",
       " ('peuvent', 2016),\n",
       " ('mesures', 2013),\n",
       " ('reste', 2007),\n",
       " ('agents', 2005),\n",
       " ('adjudication', 2002),\n",
       " ('emprunt', 1997),\n",
       " ('autorité', 1984),\n",
       " ('adopté', 1983),\n",
       " ('propriété', 1980),\n",
       " ('montant', 1977),\n",
       " ('plan', 1972),\n",
       " ('justice', 1969),\n",
       " ('rapports', 1957),\n",
       " ('cause', 1953),\n",
       " ('vandergeten', 1953),\n",
       " ('dame', 1950),\n",
       " ('pris', 1939),\n",
       " ('demander', 1936),\n",
       " ('trop', 1931),\n",
       " ('devoir', 1931),\n",
       " ('donné', 1928),\n",
       " ('disposition', 1921),\n",
       " ('voitures', 1921),\n",
       " ('moyenne', 1913),\n",
       " ('compagnie', 1912),\n",
       " ('décision', 1908),\n",
       " ('acte', 1885),\n",
       " ('première', 1873),\n",
       " ('eaux', 1861),\n",
       " ('ministre', 1858),\n",
       " ('comptes', 1847),\n",
       " ('remarquer', 1836),\n",
       " ('propositions', 1829),\n",
       " ('concessions', 1827),\n",
       " ('porte', 1822),\n",
       " ('paiement', 1819),\n",
       " ('émis', 1815),\n",
       " ('nouvelles', 1814),\n",
       " ('membre', 1808),\n",
       " ('pense', 1805),\n",
       " ('habitants', 1795),\n",
       " ('legs', 1795),\n",
       " ('capital', 1794),\n",
       " ('pouvons', 1790),\n",
       " ('lors', 1773),\n",
       " ('hospice', 1769),\n",
       " ('élé', 1761),\n",
       " ('théâtre', 1760),\n",
       " ('suit', 1752),\n",
       " ('bois', 1736),\n",
       " ('établir', 1733),\n",
       " ('chemin', 1726),\n",
       " ('voici', 1720),\n",
       " ('andré', 1714),\n",
       " ('division', 1711),\n",
       " ('certain', 1711),\n",
       " ('mise', 1698),\n",
       " ('façon', 1698),\n",
       " ('contrat', 1694),\n",
       " ('corps', 1691),\n",
       " ('lorsqu', 1681),\n",
       " ('titre', 1676),\n",
       " ('chapitre', 1675),\n",
       " ('concours', 1662),\n",
       " ('compris', 1655),\n",
       " ('conseillers', 1646),\n",
       " ('acquisition', 1636),\n",
       " ('ensemble', 1634),\n",
       " ('absolument', 1633),\n",
       " ('convention', 1630),\n",
       " ('nécessaires', 1628),\n",
       " ('vol', 1613),\n",
       " ('nouveaux', 1606),\n",
       " ('courant', 1606),\n",
       " ('locaux', 1605),\n",
       " ('certaines', 1601),\n",
       " ('bulletin', 1599),\n",
       " ('secret', 1598),\n",
       " ('soumis', 1597),\n",
       " ('jean', 1594),\n",
       " ('recette', 1590),\n",
       " ('admis', 1590),\n",
       " ('principe', 1585),\n",
       " ('examiner', 1581),\n",
       " ('filles', 1580),\n",
       " ('neybergh', 1580),\n",
       " ('députation', 1573),\n",
       " ('immeubles', 1568),\n",
       " ('heure', 1563),\n",
       " ('modifications', 1549),\n",
       " ('demandé', 1546),\n",
       " ('bon', 1545),\n",
       " ('fonctions', 1543),\n",
       " ('employés', 1542),\n",
       " ('appel', 1540),\n",
       " ('ancien', 1537),\n",
       " ('obtenir', 1534),\n",
       " ('jours', 1534),\n",
       " ('observation', 1533),\n",
       " ('conséquence', 1523),\n",
       " ('pourquoi', 1523),\n",
       " ('garde', 1514),\n",
       " ('remboursement', 1513),\n",
       " ('certains', 1513),\n",
       " ('pauvres', 1507),\n",
       " ('déficit', 1505),\n",
       " ('égout', 1481),\n",
       " ('seul', 1470),\n",
       " ('province', 1466),\n",
       " ('boulevard', 1462),\n",
       " ('crédits', 1460),\n",
       " ('parfaitement', 1456),\n",
       " ('allocation', 1448),\n",
       " ('excédent', 1447),\n",
       " ('système', 1440),\n",
       " ('pavage', 1436),\n",
       " ('dispositions', 1435),\n",
       " ('faits', 1431),\n",
       " ('émettre', 1428),\n",
       " ('communaux', 1428),\n",
       " ('but', 1421),\n",
       " ('suivante', 1410),\n",
       " ('semble', 1408),\n",
       " ('pensions', 1407),\n",
       " ('décès', 1406),\n",
       " ('unanimité', 1405),\n",
       " ('hôpital', 1401),\n",
       " ('contraire', 1397),\n",
       " ('ecole', 1396),\n",
       " ('occasion', 1394),\n",
       " ('surtout', 1394),\n",
       " ('côté', 1392),\n",
       " ('taxes', 1390),\n",
       " ('exploitation', 1389),\n",
       " ('extraordinaire', 1382),\n",
       " ('ligne', 1377),\n",
       " ('tableau', 1376),\n",
       " ('primaire', 1376),\n",
       " ('voirie', 1374),\n",
       " ('générale', 1372),\n",
       " ('mieux', 1369),\n",
       " ('lecture', 1368),\n",
       " ('délibération', 1368),\n",
       " ('adoption', 1366),\n",
       " ('publiques', 1365),\n",
       " ('renseignements', 1365),\n",
       " ('biens', 1363),\n",
       " ('environ', 1354),\n",
       " ('parc', 1354),\n",
       " ('enfin', 1352),\n",
       " ('faveur', 1350),\n",
       " ('décidé', 1348),\n",
       " ('rendre', 1344),\n",
       " ('présente', 1342),\n",
       " ('parole', 1338),\n",
       " ('suppression', 1335),\n",
       " ('nécessité', 1334),\n",
       " ('indigents', 1331),\n",
       " ('fin', 1328),\n",
       " ('résultat', 1324),\n",
       " ('molenbeek', 1324),\n",
       " ('subsides', 1322),\n",
       " ('quelle', 1320),\n",
       " ('voter', 1319),\n",
       " ('yseux', 1318),\n",
       " ('avenir', 1317),\n",
       " ('voté', 1314),\n",
       " ('création', 1313),\n",
       " ('budgets', 1311),\n",
       " ('faisant', 1308),\n",
       " ('revenu', 1306),\n",
       " ('directeur', 1306),\n",
       " ('domicile', 1302),\n",
       " ('voies', 1300),\n",
       " ('considérable', 1297),\n",
       " ('classes', 1295),\n",
       " ('indemnité', 1288),\n",
       " ('actes', 1281),\n",
       " ('millions', 1281),\n",
       " ('chiffres', 1280),\n",
       " ('usine', 1271),\n",
       " ('senne', 1267),\n",
       " ('connaître', 1265),\n",
       " ('objets', 1264),\n",
       " ('ouvriers', 1263),\n",
       " ('hommes', 1260),\n",
       " ('impossible', 1259),\n",
       " ('obligations', 1258),\n",
       " ('ordinaire', 1258),\n",
       " ('anvers', 1254),\n",
       " ('action', 1250),\n",
       " ('verhoeven', 1248),\n",
       " ('telle', 1246),\n",
       " ('autant', 1245),\n",
       " ('palais', 1244),\n",
       " ('établissements', 1238),\n",
       " ('hôtel', 1237),\n",
       " ('outre', 1234),\n",
       " ('sens', 1232),\n",
       " ('primaires', 1231),\n",
       " ('plans', 1229),\n",
       " ('existe', 1228),\n",
       " ('entendu', 1228),\n",
       " ('réserve', 1221),\n",
       " ('sainte', 1217),\n",
       " ('élève', 1216),\n",
       " ('questions', 1209),\n",
       " ('différence', 1206),\n",
       " ('commerce', 1203),\n",
       " ('incendie', 1197),\n",
       " ('puisque', 1195),\n",
       " ('notamment', 1195),\n",
       " ('bonne', 1194),\n",
       " ('terre', 1193),\n",
       " ('présents', 1191),\n",
       " ('conseiller', 1191),\n",
       " ('présent', 1187),\n",
       " ('poisson', 1185),\n",
       " ('termes', 1184),\n",
       " ('flamand', 1183),\n",
       " ('chauffage', 1174),\n",
       " ('seule', 1172),\n",
       " ('malades', 1168),\n",
       " ('matériel', 1167),\n",
       " ('cour', 1167),\n",
       " ('monsieur', 1161),\n",
       " ('loyer', 1161),\n",
       " ('égard', 1160),\n",
       " ('font', 1158),\n",
       " ('achat', 1158),\n",
       " ('lequel', 1156),\n",
       " ('organisation', 1156),\n",
       " ('modification', 1155),\n",
       " ('immédiatement', 1150),\n",
       " ('hôpitaux', 1145),\n",
       " ('janson', 1145),\n",
       " ('taux', 1144),\n",
       " ('établi', 1143),\n",
       " ('prochaine', 1142),\n",
       " ('présence', 1141),\n",
       " ('dépôt', 1139),\n",
       " ('adoptées', 1138),\n",
       " ('délai', 1134),\n",
       " ('utilité', 1128),\n",
       " ('fort', 1128),\n",
       " ('territoire', 1127),\n",
       " ('choses', 1125),\n",
       " ('puisse', 1124),\n",
       " ('affaires', 1122),\n",
       " ('articles', 1121),\n",
       " ('devait', 1119),\n",
       " ('spécial', 1116),\n",
       " ('suivants', 1115),\n",
       " ('explications', 1113),\n",
       " ('communication', 1112),\n",
       " ('soumettre', 1111),\n",
       " ('nomination', 1107),\n",
       " ('opinion', 1107),\n",
       " ('importance', 1106),\n",
       " ('usage', 1105),\n",
       " ('supérieure', 1103),\n",
       " ('application', 1102),\n",
       " ('pièces', 1098),\n",
       " ('réduction', 1098),\n",
       " ('diminution', 1093),\n",
       " ('intérieur', 1092),\n",
       " ('voilà', 1092),\n",
       " ('intervention', 1090),\n",
       " ('mêmes', 1089),\n",
       " ('actuel', 1087),\n",
       " ('exemple', 1083),\n",
       " ('chaussée', 1082),\n",
       " ('concessionnaire', 1082),\n",
       " ('esl', 1081),\n",
       " ('égouts', 1079),\n",
       " ('époque', 1075),\n",
       " ('echevins', 1070),\n",
       " ('kops', 1070),\n",
       " ('verbal', 1069),\n",
       " ('argent', 1069),\n",
       " ('prise', 1068),\n",
       " ('transformation', 1067),\n",
       " ('emplacement', 1066),\n",
       " ('pays', 1063),\n",
       " ('ensuite', 1060),\n",
       " ('mètre', 1060),\n",
       " ('obtenu', 1059),\n",
       " ('attention', 1055),\n",
       " ('contentieux', 1052),\n",
       " ('annuités', 1052),\n",
       " ('spéciale', 1048),\n",
       " ('mobilier', 1045),\n",
       " ('places', 1044),\n",
       " ('urgence', 1043),\n",
       " ('distribution', 1040),\n",
       " ('longtemps', 1039),\n",
       " ('fabriques', 1039),\n",
       " ('janssen', 1039),\n",
       " ('comment', 1038),\n",
       " ('vertu', 1035),\n",
       " ('conformément', 1032),\n",
       " ('instituteurs', 1029),\n",
       " ('entreprise', 1029),\n",
       " ('propriétaires', 1028),\n",
       " ('sépulture', 1027),\n",
       " ('sollicite', 1025),\n",
       " ('hygiène', 1025),\n",
       " ('solution', 1024),\n",
       " ('contributions', 1021),\n",
       " ('salle', 1016),\n",
       " ('potter', 1015),\n",
       " ('utile', 1012),\n",
       " ('accorder', 1008),\n",
       " ('consommation', 1005),\n",
       " ('pilloy', 1004),\n",
       " ('vander', 1003),\n",
       " ('profit', 1000),\n",
       " ('eglise', 997),\n",
       " ('assurer', 995),\n",
       " ('sauf', 994),\n",
       " ('maladies', 994)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "DECADE = '1880'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"188.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(500)"
   ]
  },
  {
   "source": [
    "1890"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1890'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"189.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(800)"
   ]
  },
  {
   "source": [
    "1900"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1900'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"190.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(800)"
   ]
  },
  {
   "source": [
    "1910"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1910'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"191.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(800)"
   ]
  },
  {
   "source": [
    "1920"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1920'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"192.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(800)"
   ]
  },
  {
   "source": [
    "1930"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1930'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"193.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(800)"
   ]
  },
  {
   "source": [
    "1940"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1940'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"194.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(800)"
   ]
  },
  {
   "source": [
    "1950"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1950'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"195.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(800)"
   ]
  },
  {
   "source": [
    "1960"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1960'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"196.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(800)"
   ]
  },
  {
   "source": [
    "1970"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1970'\n",
    "\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]\n",
    "txts = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(f'{data_path}/{txt}', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "with open(f'{DECADE[:-1]}.txt', 'r', encoding='utf-8' ) as f:\n",
    "    before = f.read()\n",
    "\n",
    "from filtering import filtering\n",
    "\n",
    "filtering(DECADE[:-1])\n",
    "\n",
    "path = \"197.txt\"\n",
    "limit = 10**8\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()[:limit]\n",
    "\n",
    "# détecter les mots\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")\n",
    "\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")\n",
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(800)"
   ]
  },
  {
   "source": [
    "## Création d'une liste de stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}