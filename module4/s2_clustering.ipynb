{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b035f594501fd99b0ba4fdbf39dd3ef4592c3539e4ec00f8ba05c88e0c5143ba"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\emeld\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/txt/\""
   ]
  },
  {
   "source": [
    "# Choix d'une décennie et du nombre de clusters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1870'\n",
    "N_CLUSTERS = 5"
   ]
  },
  {
   "source": [
    "# Chargement des fichiers de la décennie"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Bxl_1870_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1870_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1870_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1870_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1870_Tome_I1_Part_5.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Exemple de fichiers\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [open(data_path + f, encoding='utf8', errors='ignore').read() for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'VILLE\\n\\nDE\\n\\nBRUXELLES.\\n\\nBULLETIN COMMUNAL.\\nA N N É E\\n\\nP R E M I E R\\n\\n1870.\\n\\nS E M E S T R E .\\n\\nBRUXELLES,\\nIMPRIMERIE\\n\\nBOLS-WITTOUCK.\\n\\n\\x0cï\\n\\nSo\\ni\\n»\\n\\n1\\n\\nV\\n\\nFu\\n\\nte\\n\\nG)\\n\\ni\\n\\nÛ\\n\\n\\x0cVILLE DE BRUXELLES.\\n\\nBULLETIN\\n\\nCOMMUNAL.\\n\\nA N N É E 1870.\\n\\nNUMÉRO 1 .\\n\\nSAMEDI 1\\n\\ner\\n\\nCONSEIL\\n\\ner\\n\\nJANVIER.\\n\\nCOMMUNAL.\\n\\nSéance du 1 janvier 1870.\\ner\\n\\nPrésidence de M. JULES ANSPACH, Bourgmestre.\\n\\n— Prestation de serment et installa'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Exemple de textes\n",
    "texts[0][:400]"
   ]
  },
  {
   "source": [
    "# Vectorisation du texte"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, stem=True):\n",
    "    \"\"\" Tokenize text and remove punctuation \"\"\"\n",
    "    text = text.translate(string.punctuation)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=process_text,\n",
    "                                stop_words=stopwords.words('french'),\n",
    "                                max_df=0.5,\n",
    "                                min_df=0.1,\n",
    "                                lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%time tfidf_vectors = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<111x8170 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 199143 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "bochart        0.371732\n",
       "pavés          0.176135\n",
       "statue         0.163264\n",
       "anglaise       0.157298\n",
       "jottrand       0.150558\n",
       "                 ...   \n",
       "lorsqu'ils     0.000000\n",
       "lorsqu'un      0.000000\n",
       "los            0.000000\n",
       "lotissement    0.000000\n",
       "#              0.000000\n",
       "Length: 8170, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Exemple de vecteur TFIDF\n",
    "pd.Series(\n",
    "    tfidf_vectors[0].toarray()[0],\n",
    "    index=vectorizer.get_feature_names()\n",
    "    ).sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "# Clustering des vecteurs TFIDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_model = KMeans(n_clusters=N_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "km_model.fit(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = collections.defaultdict(list)\n",
    "\n",
    "for idx, label in enumerate(km_model.labels_):\n",
    "    clustering[label].append(files[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: ['Bxl_1872_Tome_II1_Part_4.txt',\n     'Bxl_1872_Tome_II1_Part_5.txt',\n     'Bxl_1873_Tome_I1_Part_1.txt',\n     'Bxl_1873_Tome_I1_Part_2.txt',\n     'Bxl_1873_Tome_I1_Part_3.txt',\n     'Bxl_1874_Tome_I1_Part_1.txt',\n     'Bxl_1874_Tome_I1_Part_2.txt',\n     'Bxl_1874_Tome_I1_Part_3.txt',\n     'Bxl_1874_Tome_I1_Part_4.txt',\n     'Bxl_1874_Tome_I1_Part_5.txt',\n     'Bxl_1876_Tome_I1_Part_1.txt',\n     'Bxl_1876_Tome_I1_Part_2.txt',\n     'Bxl_1876_Tome_I1_Part_3.txt',\n     'Bxl_1876_Tome_II1_Part_1.txt',\n     'Bxl_1876_Tome_II1_Part_4.txt',\n     'Bxl_1876_Tome_II1_Part_5.txt',\n     'Bxl_1877_Tome_I1_Part_1.txt',\n     'Bxl_1877_Tome_I1_Part_2.txt',\n     'Bxl_1877_Tome_I1_Part_3.txt',\n     'Bxl_1877_Tome_I1_Part_4.txt',\n     'Bxl_1877_Tome_II1_Part_1.txt',\n     'Bxl_1877_Tome_II1_Part_2.txt',\n     'Bxl_1877_Tome_II1_Part_6.txt',\n     'Bxl_1877_Tome_II1_Part_7.txt',\n     'Bxl_1878_Tome_I1_Part_1.txt',\n     'Bxl_1878_Tome_I1_Part_2.txt',\n     'Bxl_1878_Tome_I1_Part_3.txt',\n     'Bxl_1878_Tome_I1_Part_4.txt',\n     'Bxl_1878_Tome_II1_Part_1.txt',\n     'Bxl_1878_Tome_II1_Part_5.txt',\n     'Bxl_1879_Tome_I1_Part_1.txt',\n     'Bxl_1879_Tome_I1_Part_2.txt',\n     'Bxl_1879_Tome_I1_Part_3.txt',\n     'Bxl_1879_Tome_I1_Part_4.txt',\n     'Bxl_1879_Tome_I1_Part_5.txt',\n     'Bxl_1879_Tome_II1_Part_1.txt',\n     'Bxl_1879_Tome_II1_Part_10.txt',\n     'Bxl_1879_Tome_II1_Part_2.txt',\n     'Bxl_1879_Tome_II1_Part_6.txt',\n     'Bxl_1879_Tome_II1_Part_7.txt',\n     'Bxl_1879_Tome_II1_Part_9.txt'],\n 1: ['Bxl_1870_Tome_I1_Part_1.txt',\n     'Bxl_1870_Tome_I1_Part_2.txt',\n     'Bxl_1870_Tome_I1_Part_3.txt',\n     'Bxl_1870_Tome_I1_Part_4.txt',\n     'Bxl_1870_Tome_I1_Part_5.txt',\n     'Bxl_1870_Tome_II1_Part_1.txt',\n     'Bxl_1870_Tome_II1_Part_3.txt',\n     'Bxl_1870_Tome_II1_Part_4.txt',\n     'Bxl_1870_Tome_II1_Part_5.txt',\n     'Bxl_1870_Tome_II1_Part_6.txt',\n     'Bxl_1871_Tome_I1_Part_1.txt',\n     'Bxl_1871_Tome_I1_Part_2.txt',\n     'Bxl_1871_Tome_I1_Part_3.txt',\n     'Bxl_1871_Tome_I1_Part_4.txt',\n     'Bxl_1871_Tome_I1_Part_5.txt',\n     'Bxl_1871_Tome_II1_Part_1.txt',\n     'Bxl_1871_Tome_II1_Part_4.txt',\n     'Bxl_1871_Tome_II1_Part_5.txt',\n     'Bxl_1871_Tome_II1_Part_6.txt',\n     'Bxl_1871_Tome_II1_Part_7.txt',\n     'Bxl_1872_Tome_I1_Part_1.txt',\n     'Bxl_1872_Tome_I1_Part_2.txt',\n     'Bxl_1872_Tome_I1_Part_3.txt',\n     'Bxl_1872_Tome_II1_Part_1.txt'],\n 2: ['Bxl_1870_Tome_II1_Part_2.txt',\n     'Bxl_1871_Tome_II1_Part_2.txt',\n     'Bxl_1871_Tome_II1_Part_3.txt',\n     'Bxl_1872_Tome_II1_Part_2.txt',\n     'Bxl_1872_Tome_II1_Part_3.txt',\n     'Bxl_1876_Tome_II1_Part_2.txt',\n     'Bxl_1876_Tome_II1_Part_3.txt',\n     'Bxl_1877_Tome_II1_Part_3.txt',\n     'Bxl_1877_Tome_II1_Part_4.txt',\n     'Bxl_1877_Tome_II1_Part_5.txt',\n     'Bxl_1878_Tome_II1_Part_2.txt',\n     'Bxl_1878_Tome_II1_Part_3.txt',\n     'Bxl_1878_Tome_II1_Part_4.txt',\n     'Bxl_1879_Tome_II1_Part_11.txt',\n     'Bxl_1879_Tome_II1_Part_3.txt',\n     'Bxl_1879_Tome_II1_Part_4.txt',\n     'Bxl_1879_Tome_II1_Part_5.txt',\n     'Bxl_1879_Tome_II1_Part_8.txt',\n     'Lkn_1879_Tome_I_Part_1.txt',\n     'Lkn_1879_Tome_I_Part_2.txt',\n     'Lkn_1879_Tome_I_Part_3.txt',\n     'Lkn_1879_Tome_I_Part_4.txt',\n     'Lkn_1879_Tome_I_Part_5.txt',\n     'Lkn_1879_Tome_I_Part_6.txt'],\n 3: ['Lkn_1874_Tome_RptAn_Part_1.txt',\n     'Lkn_1874_Tome_RptAn_Part_2.txt',\n     'Lkn_1874_Tome_RptAn_Part_3.txt',\n     'Lkn_1874_Tome_RptAn_Part_4.txt',\n     'Lkn_1874_Tome_RptAn_Part_5.txt',\n     'Lkn_1874_Tome_RptAn_Part_6.txt',\n     'Lkn_1874_Tome_RptAn_Part_7.txt',\n     'Lkn_1874_Tome_RptAn_Part_8.txt',\n     'Lkn_1874_Tome_RptAn_Part_9.txt'],\n 4: ['Bxl_1870_Tome_I1_Part_6.txt',\n     'Bxl_1870_Tome_II1_Part_7.txt',\n     'Bxl_1871_Tome_II1_Part_8.txt',\n     'Bxl_1872_Tome_I1_Part_4.txt',\n     'Bxl_1872_Tome_II1_Part_6.txt',\n     'Bxl_1873_Tome_I1_Part_4.txt',\n     'Bxl_1876_Tome_I1_Part_4.txt',\n     'Bxl_1876_Tome_II1_Part_6.txt',\n     'Bxl_1877_Tome_I1_Part_5.txt',\n     'Bxl_1877_Tome_II1_Part_8.txt',\n     'Bxl_1878_Tome_I1_Part_5.txt',\n     'Bxl_1878_Tome_II1_Part_6.txt',\n     'Lkn_1874_Tome_RptAn_Part_10.txt']}\n"
     ]
    }
   ],
   "source": [
    "pprint(dict(clustering))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}